{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 明星主页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_starpage(cookie: str):\n",
    "    names = ['tnt', 'mjq', 'dcx', 'syx', 'lyw', 'zzy', 'yhx', 'hjl']\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "    result['rank'] = list(range(1,101))\n",
    "\n",
    "    total_number = []\n",
    "    headers = {'Cookie': cookie}\n",
    "    \n",
    "    for i in range(1, 9):\n",
    "        session = requests.Session()\n",
    "\n",
    "        #url for every page\n",
    "        url = 'https://www.tfent.cn/TYFansClub/pageRank.html?uid=' + str(i) \n",
    "        #scrape data\n",
    "        response = session.get(url, headers=headers)\n",
    "        html_doc = response.text\n",
    "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "        #get total number of sunflower this month so far\n",
    "        if i == 1: \n",
    "            total = soup.findAll('div', {'class': 'unlock'})\n",
    "        else:\n",
    "            total = soup.findAll('div', {'class': 'unlock '+ names[i-1]})\n",
    "        total_number.append(total[0].find('p').get_text().split(\"：\")[1])\n",
    "\n",
    "        # top 100 contribution \n",
    "        rank = soup.findAll('div', {'class':'board'})\n",
    "        allrank = rank[0].find_all('div', {'class':['rank-number', 'name', 'value']})\n",
    "        cleaned_rank = []\n",
    "        for p in range(len(allrank)):\n",
    "            cleaned_rank.append(allrank[p].get_text())\n",
    "\n",
    "        columns = [\"rank\", names[i-1]+\"_name\", names[i-1]+\"_sunflower\"]\n",
    "        temp = pd.DataFrame(columns = columns)\n",
    "\n",
    "        #rearrange data to correct column\n",
    "        for j in range(len(cleaned_rank)):\n",
    "            if j % 3 == 0:\n",
    "                temp.loc[j, 'rank'] = int(cleaned_rank[j])\n",
    "            elif j % 3 == 1:\n",
    "                temp.loc[j-1, columns[1]] = cleaned_rank[j]\n",
    "            elif j % 3 == 2:\n",
    "                temp.loc[j-2, columns[2]] = cleaned_rank[j][:-3]\n",
    "\n",
    "        #append this page's data to ultimate outputs\n",
    "        result = pd.merge(result, temp, on=\"rank\")\n",
    "        print(\"Page\", names[i-1], \"is scraped.\")\n",
    "    return total_number, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page tnt is scraped.\n",
      "Page mjq is scraped.\n",
      "Page dcx is scraped.\n",
      "Page syx is scraped.\n",
      "Page lyw is scraped.\n",
      "Page zzy is scraped.\n",
      "Page yhx is scraped.\n",
      "Page hjl is scraped.\n"
     ]
    }
   ],
   "source": [
    "cookie = \"PHPSESSID=rlb5bqd31vdcknc2ig6oe4q5n3; UM_distinctid=177692148b144c-04833e79061027-163c655d-13c680-177692148b2987; msgPage=3; CNZZDATA1274712623=1121232681-1612376524-%7C1612539378\"\n",
    "total_number, result = scrape_starpage(cookie)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_starpage(folder, result):\n",
    "    today = datetime.today().strftime('%Y_%m_%d_%H_%M')\n",
    "\n",
    "    filename = folder + \"/starPage_\" + str(today) + '.csv'\n",
    "    result.to_csv(filename, index=False, encoding='utf-8')\n",
    "    return\n",
    "\n",
    "save_starpage(\"二月小葵明星主页\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#小葵花总数\n",
    "\n",
    "def save_total(filename, total_number):\n",
    "    try:\n",
    "        total = pd.read_csv(filename)\n",
    "    except FileNotFoundError:\n",
    "        total = pd.DataFrame(columns = ['date', 'time', 'tnt', 'mjq', 'dcx', 'syx', 'lyw', 'zzy', 'yhx', 'hjl'])\n",
    "    row = [datetime.today().strftime('%m/%d/%y'), datetime.today().strftime('%H:%M')]\n",
    "    for i in total_number:\n",
    "        row.append(i)\n",
    "\n",
    "    row = pd.DataFrame([row], columns = total.columns)\n",
    "    total = total.append(row, ignore_index=True)\n",
    "    total.to_csv(filename, index=False)\n",
    "    return\n",
    "    \n",
    "    \n",
    "save_total('totalSunflower_2021年2月.csv', total_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 留言板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may take days\n",
    "def scrape_comments(cookie: str): \n",
    "    headers = {\n",
    "    'Cookie': cookie\n",
    "    }\n",
    "    comments = pd.DataFrame(columns = ['user', 'time', 'title', 'content', 'likes', 'replies'])\n",
    "\n",
    "    #need to update total date range\n",
    "    for i in range(1, 21145):\n",
    "        session = requests.Session()\n",
    "\n",
    "        url = 'https://www.tfent.cn/TYFansClub/messages?page=' + str(i)\n",
    "        #scrape data\n",
    "        response = session.get(url, headers=headers)\n",
    "        html_doc = response.text\n",
    "        soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "\n",
    "\n",
    "        message = soup.findAll('ul', {'class': 'messageList'})\n",
    "\n",
    "        message = message[0].find_all('div', {'class':['info']})\n",
    "        for m in message:\n",
    "\n",
    "            user = m.find_all('h3', {'class':['name lf']})[0].get_text()\n",
    "            time = m.find_all('span', {'class':['time lf']})[0].get_text()\n",
    "            title = m.find_all('h3', {'class':['tit']})[0].get_text()\n",
    "            content = m.find_all('p')[0].get_text()\n",
    "            likes = int(m.find_all('a', {'class':['tp']})[0].get_text())\n",
    "            replies =  int(m.find_all('a', {'class':['cm']})[0].get_text())\n",
    "\n",
    "            record = [[user, time, title, content, likes, replies]]\n",
    "            record = pd.DataFrame(record,columns=['user', 'time', 'title', 'content', 'likes', 'replies'])\n",
    "            comments = comments.append(record, ignore_index=True)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(i, 'pages scraped.')\n",
    "    \n",
    "    comments.to_csv('comments.csv')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105715</th>\n",
       "      <td>长风拂棋</td>\n",
       "      <td>2018/10/09 22:03</td>\n",
       "      <td>to祺祺，程程，tyt</td>\n",
       "      <td>小朋友们加油啊，姐姐一直支持你们哦，姐姐还把两个从不追星的闺蜜拉进来了，都是你们太优秀啦，群...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105716</th>\n",
       "      <td>狼崽的猪猪是...</td>\n",
       "      <td>2018/10/09 21:58</td>\n",
       "      <td>狼崽</td>\n",
       "      <td>鹅子，晚安，早点休息，坚持，加油，你会越来越好的，不要有太大的压力，加油，麻麻爱你</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105717</th>\n",
       "      <td>一文酱紫</td>\n",
       "      <td>2018/10/09 16:00</td>\n",
       "      <td>To TYT</td>\n",
       "      <td>你们都是特别的存在，都给我好好加油！TYT冲啊！</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105718</th>\n",
       "      <td>我不是葫芦娃</td>\n",
       "      <td>2018/10/09 12:52</td>\n",
       "      <td>To: 嘉祺</td>\n",
       "      <td>还有小宝现在在长身体不要驼背哦。</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105719</th>\n",
       "      <td>我不是葫芦娃</td>\n",
       "      <td>2018/10/09 12:51</td>\n",
       "      <td>To: 嘉祺</td>\n",
       "      <td>每天都要开开心心的呀! ! !</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user              time        title  \\\n",
       "105715       长风拂棋  2018/10/09 22:03  to祺祺，程程，tyt   \n",
       "105716  狼崽的猪猪是...  2018/10/09 21:58           狼崽   \n",
       "105717       一文酱紫  2018/10/09 16:00       To TYT   \n",
       "105718     我不是葫芦娃  2018/10/09 12:52       To: 嘉祺   \n",
       "105719     我不是葫芦娃  2018/10/09 12:51       To: 嘉祺   \n",
       "\n",
       "                                                  content likes replies  \n",
       "105715  小朋友们加油啊，姐姐一直支持你们哦，姐姐还把两个从不追星的闺蜜拉进来了，都是你们太优秀啦，群...     1       0  \n",
       "105716          鹅子，晚安，早点休息，坚持，加油，你会越来越好的，不要有太大的压力，加油，麻麻爱你     0       0  \n",
       "105717                           你们都是特别的存在，都给我好好加油！TYT冲啊！     1       0  \n",
       "105718                                   还有小宝现在在长身体不要驼背哦。     0       0  \n",
       "105719                                   每天都要开开心心的呀! ! !      0       0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "references:\n",
    "1. https://www.cnblogs.com/sanduzxcvbnm/p/10276583.html\n",
    "2. https://netnewpower.net/?p=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
